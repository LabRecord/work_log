> [原文链接](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/)

----------
# Mel Frequency Cepstral Coefficient (MFCC) tutorial

任何自动语音识别系统的第一步是提取特征，即识别音频信号的组成部分，这些组成部分有助于识别语言内容并丢弃所有其他携带诸如背景噪声，情绪等信息的东西。

理解语音的要点是人类产生的声音被声道的形状过滤，包括舌头，牙齿等。这种形状决定了声音的来源。如果我们能够准确地确定形状，这应该能够准确地表示正在产生的音素( [phoneme](https://en.wikipedia.org/wiki/Phoneme))。声道的形状表现在短时功率谱的包络中，MFCC的工作是准确地表示这个包络。

Mel频率倒谱系数（MFCC）是一种广泛用于自动语音和说话人识别的功能。它们是Davis和Mermelstein在20世纪80年代引入的，从那以后一直是最先进的。

在引入MFCC之前，线性预测系数（LPC）和线性预测倒谱系数（LPCC）（[a tutorial on cepstrum and LPCCs](http://www.practicalcryptography.com/miscellaneous/machine-learning/tutorial-cepstrum-and-lpccs/)）是自动语音识别（ASR）的主要特征类型，特别是对于[HMM](http://practicalcryptography.com/miscellaneous/machine-learning/hidden-markov-model-hmm-tutorial/)分类器。这里将介绍MFCC的主要方面，为什么它们为ASR提供了一个很好的功能，以及如何实现它们。

----------
# Steps at a Glance 

> 
1. Frame the signal into short frames.
2. For each frame calculate the periodogram estimate 3. of the power spectrum.
4. Apply the mel filterbank to the power spectra, sum the energy in each filter.
5. Take the logarithm of all filterbank energies.
6. Take the DCT of the log filterbank energies.
7. Keep DCT coefficients 2-13, discard the rest.


> There are a few more things commonly done, sometimes the frame energy is appended to each feature vector. Delta and Delta-Delta features are usually also appended. Liftering is also commonly applied to the final features.

 1. 将信号帧化为短帧。
 2. 对于每个帧，计算功率谱的周期图估计([ periodogram estimate](https://en.wikipedia.org/wiki/Periodogram))。
 3. 将mel滤波器组应用于功率谱，将每个滤波器中的能量相加。
 4. 取所有滤波器组能量的对数。
 5. 获取日志滤波器组能量的DCT。
 6. 保持DCT系数2-13，丢弃其余部分。


还有一些常见的事情，有时帧能量被附加到每个特征向量。

Delta和Delta-Delta功能通常也会附加。

Liftering也常用于最终功能。
 
----------
# Why do we do these things?

现在我们将更慢地完成这些步骤并解释为什么每个步骤都是必要的。

音频信号不断变化，所以为了简化事情我们假设在短时间尺度上音频信号没有太大变化（当我们说它没有变化时，我们的意思是统计上，即统计上静止，显然样本不断变化甚至短时间尺度）。这就是我们将信号帧化为20-40ms帧的原因。如果帧短得多，我们没有足够的样本来获得可靠的频谱估计，如果帧越长，信号在整个帧中变化太大。

下一步是计算每帧的功率谱。这是由人耳蜗（耳朵中的器官）驱动的，其根据传入声音的频率在不同的点处振动。根据耳蜗中振动的位置（摆动小毛发），不同的神经会向大脑发出消息，告知大脑存在某些频率。我们的周期图估计为我们执行类似的工作，识别帧中存在哪些频率。

周期图频谱估计仍然包含自动语音识别（ASR）不需要的许多信息。特别地，耳蜗不能辨别两个紧密间隔的频率之间的差异。随着频率的增加，这种效果变得更加明显。出于这个原因，我们采集了一些周期图箱，并总结它们，以了解不同频率区域存在多少能量。这是由我们的Mel滤波器组执行的：第一个滤波器非常窄，并指示在0赫兹附近存在多少能量。随着频率越来越高，我们的滤波器越来越宽，因为我们越来越不关心变化。我们只关心每个点大概产生多少能量。Mel刻度告诉我们如何隔离我们的滤波器组以及制作它们的宽度。见下文 如何计算间距。

一旦我们有了滤波器组能量，我们就取它们的对数。这也是人类听觉的动机：我们没有听到线性音阶的响度。通常，为了使声音的体积增加一倍，我们需要将8倍的能量投入其中。这意味着如果声音开始响起，那么能量的大的变化可能听起来不那么不同。这种压缩操作使我们的功能与人类实际听到的功能更加匹配。为什么是对数而不是立方根？对数允许我们使用倒频谱平均减法，这是一种信道归一化技术。

最后一步是计算对数滤波器组能量的DCT。这有两个主要原因。因为我们的滤波器组都是重叠的，所以滤波器组能量彼此非常相关。DCT对能量进行去相关，这意味着对角线协方差矩阵可用于对例如HMM分类器中的特征进行建模。但请注意，26个DCT系数中只有12个被保留。这是因为较高的DCT系数代表滤波器组能量的快速变化，并且事实证明这些快速变化实际上降低了ASR性能，因此我们通过丢弃它们获得了小的改进。

----------
# What is the Mel scale?

![1](https://leanote.com/api/file/getImage?fileId=5b6bab46ab64412ef4000af4)

----------
# Implementation steps

![2](https://leanote.com/api/file/getImage?fileId=5b6bab8cab64412d09000a5a)
![3](https://leanote.com/api/file/getImage?fileId=5b6bac0eab64412ef4000b18)

----------
# Computing the Mel filterbank

![4](https://leanote.com/api/file/getImage?fileId=5b6bac46ab64412ef4000b28)
![5](https://leanote.com/api/file/getImage?fileId=5b6bac83ab64412ef4000b36)
![6](https://leanote.com/api/file/getImage?fileId=5b6bac9bab64412d09000a8c)

----------
# Deltas and Delta-Deltas

![7](https://leanote.com/api/file/getImage?fileId=5b6bacaeab64412ef4000b3b)

----------
# Implementations

> [MFCCs in python](https://github.com/jameslyons/python_speech_features)

----------
